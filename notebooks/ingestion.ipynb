{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8169519c-a098-4697-ba62-ef9aedbf0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "places_api_key = os.getenv('places_api_key')\n",
    "rapid_api_key = os.getenv('rapid_api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ecf0b",
   "metadata": {},
   "source": [
    "## 2. Data Integration Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3a365",
   "metadata": {},
   "source": [
    "### Local Attractions and Activities Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504e8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Places API\n",
    "import requests\n",
    "\n",
    "def fetch_google_places(activity, api_key):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "    params = {\n",
    "        'query': f'{activity} in barcelona',\n",
    "        'key': places_api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        places = response.json().get('results', [])\n",
    "        return [{'name': place['name'], 'address': place.get('formatted_address'), 'rating': place.get('rating')} for place in places]\n",
    "\n",
    "    else:\n",
    "        print(f\"Error fetching data from Google Places API: {response.status_code}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a5be203-b104-48c4-ae49-1afa20c29a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dict = {\"sightseeing\":[\"Historical Sites\", \"Iconic Landmarks\", \"City Tours\", \"Amusement parks\"], \n",
    "                 \"dinning\":[\"Local Cuisine\", \"Food Tours\", \"Cooking Classes\", \" Wineries and breweries\"], \n",
    "                 \"adventure\":[\"Water Sports\", \"Extreme Sports\", \"Winter Sports\", \"Cycling and Biking\"],\n",
    "                 \"relaxation\":[\"Spas\", \"Wellness Centers\", \"Yoga and Meditation\", \"Cruises\"], \n",
    "                 \"culture\":[\"Museums\", \"Galleries\", \"Theater Performances\", \"Cultural Tours\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "758018f6-1cd9-420e-9d24-da507b981e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for k,v in activity_dict.items():\n",
    "    activity = f\"{k} activities including {v[0]}, {v[1]}, {v[2]}, {v[3]}\"\n",
    "    tourist_spots = fetch_google_places(activity, places_api_key)\n",
    "    result_dict[k] = tourist_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84bb58a9-0b6f-43a9-903c-dde87ecacf43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "for activity, places in result_dict.items():\n",
    "    for place in places:\n",
    "        place[\"activity\"] = activity\n",
    "        result_list.append(place)\n",
    "\n",
    "result_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3528bc4b-cb31-4bbc-aa5c-521eac1e5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('../data/activities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4a087",
   "metadata": {},
   "source": [
    "### Travel Guides and Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c1272-2228-404e-a177-bd7de5a13b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'FILL_WITH_URL'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract blog content\n",
    "blogs = soup.find_all('p')  # Assuming blog content is wrapped in <p> tags\n",
    "for blog in blogs:\n",
    "    print(blog.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50dcf50-baac-4752-a320-bd5ac293c783",
   "metadata": {},
   "source": [
    "### Although this script fetched me some blogs, I had to do some manual data scraping to get more data. Therefore, the blogs data is stored in the travel_iterenary.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f67f3-df76-41aa-9e49-fcd566f95fc2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04337ba2-8392-4b6b-8c05-01825606a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df = pd.read_csv(\"../data/activities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d02db-e666-4c33-ae6d-d9c562dbe04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/travel_iterenary.json\"\n",
    "\n",
    "with open(file_path, \"rt\") as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "    \n",
    "def extract_text(data_entry):\n",
    "    docs_fin = {}\n",
    "    plan = \"\"\n",
    "    \n",
    "    for day in data_entry['Iterenary']:  # Fixed 'days' to 'day'\n",
    "        itinerary = \"Travel itinerary for \" + data_entry.get('duration', '') + \" days.\"\n",
    "        \n",
    "        plan += day['Plan']\n",
    "        plan += \"\\n\"\n",
    "        \n",
    "        docs_fin[\"itinerary\"] = itinerary\n",
    "        docs_fin[\"plan\"] = plan\n",
    "        \n",
    "    return docs_fin\n",
    "docs_fin = [extract_text(doc) for doc in docs_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45806dcd-959e-4277-968c-8e6eba823e88",
   "metadata": {},
   "source": [
    "## Ingest Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7933eef-6365-4720-b976-6e280a437964",
   "metadata": {},
   "source": [
    "### ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09134971-c96f-4dc7-b1d4-b22be9572415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that elastic search works\n",
    "!curl http://localhost:9200/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abb3b5-723c-4794-8bbe-d77026574618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878262ec-5a95-40d3-81ac-32acc6ca101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define index mapping\n",
    "index_mapping = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"itinerary\": {\"type\": \"text\"},  \n",
    "            \"plan\": {\"type\": \"text\"}        \n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"tip-index\"\n",
    "\n",
    "# Check if the index already exists\n",
    "# Check if the index already exists\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6b8b1-e9ba-480d-a3e2-5b40cf8d3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create index\n",
    "es_client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708d6a0-16f6-451a-9dab-d5e1203c436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index document\n",
    "for duration in tqdm(docs_fin):\n",
    "    es_client.index(index=index_name, document=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f410d1-71c3-4cae-9949-e6cbebd2d435",
   "metadata": {},
   "source": [
    "### ElasticSearch as VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629415fa-d83d-404c-a6ed-003e1720492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec = []\n",
    "for doc in docs_fin:\n",
    "    doc[\"itin_vector\"] = model.encode(doc['itinerary']).tolist()\n",
    "    doc_vec.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e06c49-57e4-4644-a32f-b4e927045af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define index mapping\n",
    "vec_index_mapping = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"itinerary\": {\"type\":\"text\"},  \n",
    "            \"plan\": {\"type\":\"text\"},\n",
    "            \"itin_vector\": {\"type\":\"dense_vector\", \"dims\":768, \"index\":True, \"similarity\":\"cosine\"} \n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"vec-index\"\n",
    "\n",
    "# Check if the index already exists\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "#create index\n",
    "es_client.indices.create(index=index_name, body=vec_index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e3a1b1-ab72-499b-a815-dcad6a436d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in tqdm(doc_vec):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291edac-dc13-49f3-a5c2-a2c53c5ed027",
   "metadata": {},
   "source": [
    "### FAISS (Facebook AI Simlarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d990431-9840-4cf3-b8a0-da43e5d2f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract relevant text from each dictionary entry\n",
    "def extract_text(data_entry):\n",
    "\n",
    "    result = data_entry.get('itinerary', '') + \"\\n\" + data_entry.get('plan', '')\n",
    "    return result.strip()\n",
    "\n",
    "# Extract all text data to be indexed\n",
    "text_data = [extract_text(entry) for entry in docs_fin]\n",
    "\n",
    "# Generate embeddings for each text using the model\n",
    "embeddings = model.encode(text_data)\n",
    "\n",
    "# Convert embeddings to a numpy array and ensure it's float32 (FAISS requires this format)\n",
    "embeddings = np.array(embeddings, dtype='float32')  # Ensure embeddings are float32\n",
    "\n",
    "# Initialize the FAISS index\n",
    "dimension = embeddings.shape[1]  # Dimension of the embedding vector\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance metric (Euclidean)\n",
    "\n",
    "# Add the embeddings to the FAISS index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index for future use\n",
    "faiss.write_index(index, 'faiss_index_file.index')\n",
    "\n",
    "print(f\"Indexed {len(embeddings)} items into FAISS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9b837-506a-4aac-a18f-526f92c70ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
